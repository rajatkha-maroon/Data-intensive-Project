{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DarshanUtils for Python\n",
    "\n",
    "This notebook gives an overwiew of features provided by the Python bindings for DarshanUtils."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default all records, metadata, available modules and the name records are loaded when opening a Darshan log:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darshan\n",
    "\n",
    "report = darshan.DarshanReport(\"example_logs/example.darshan\", read_all=True)  # Default behavior\n",
    "report.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few of the internal data structures explained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# report.metadata         # dictionary with raw metadata from darshan log\n",
    "# report.modules          # dictionary with raw module info from darshan log (need: technical, module idx)\n",
    "# report.name_records     # dictionary for resovling name records: id -> path/name\n",
    "# report.records          # per module \"dataframes\"/dictionaries holding loaded records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The darshan report holds a variety of namespaces for report related data. All of them are also referenced in `report.data` at the moment, but reliance on this internal organization of the report object is discouraged once the API stabilized. Currently, `report.data` references the following information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.mod_read_all_records('POSIX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.mod_read_all_records('STDIO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.update_name_records()\n",
    "report.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization helper used by different examples in the remainder of this notebook\n",
    "from IPython.display import display, HTML\n",
    "# usage: display(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Formats and Selectively Loading Records\n",
    "\n",
    "For memory efficiant analysis, it is possible to supress records from being loaded automatically. This is useful, for example, when analysis considers only records of a particular layer/module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darshan\n",
    "report = darshan.DarshanReport(\"example_logs/example.darshan\", read_all=False, lookup_name_records=True) # Loads no records!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected to fail, as no records were loaded\n",
    "try:\n",
    "    print(len(report.records['STDIO']), \"records loaded for STDIO.\")\n",
    "except:\n",
    "    print(\"No STDIO records loaded for this report yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional records then can be loaded selectively, for example, on a per module basis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dtype: pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.mod_read_all_records(\"STDIO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(report.records['STDIO'].to_df()['counters'])\n",
    "display(report.records['STDIO'].to_df()['fcounters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default, export to pandas dataframes using .to_df() attaches id and rank information  \n",
    "# for aggregations, this can be supressed by providing attach=None, allowing you to get plots with sensible ranges directly using pandas plotting\n",
    "report.records['STDIO'].to_df(attach=['rank'])['fcounters'].plot.box(vert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.records['STDIO'].to_df(attach=['rank'])['counters'].plot.box(vert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dtype: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.mod_read_all_records(\"STDIO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.records['STDIO'][0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dtype: numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.mod_read_all_records(\"STDIO\")\n",
    "report.records['STDIO'][0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(report.records['STDIO'][0].to_numpy()[0]['counters']))\n",
    "print(type(report.records['STDIO'][0].to_numpy()[0]['fcounters']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Darshan Log in Memory\n",
    "\n",
    "Let's have a look at how calling `report.mod_read_all_records(\"STDIO\")` changed the state of the log in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to info line: \"Loaded Records: {...}\"\n",
    "report.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When interacting on individual log data for example in a for loop you would most likely care about the following instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num records:\", len(report.records['STDIO']))\n",
    "\n",
    "# show first 10 records\n",
    "for rec in report.records['STDIO'][0:10]:\n",
    "    print(rec)\n",
    "    # do something with the record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation and Filtering (Experimental)\n",
    "\n",
    "Darshan log data is routinely aggregated for quick overview. The report object offers a few methods to perform common aggregations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report aggregations and summarization remains **experimental** for now, mostly to allow interfaces to stabilize. But experimental features can be switched on easily by invoking `darshan.enable_experimental()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darshan\n",
    "darshan.enable_experimental(verbose=True) # Enable verbosity, listing new functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example report, which counts records in log across modules \n",
    "report.name_records_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain operations like filtering and reductions\n",
    "The filter and reduce operations return DarshanReports themsleves, thus allow to convieniently chain operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "import darshan\n",
    "darshan.enable_experimental()\n",
    "\n",
    "report = darshan.DarshanReport(\"example_logs/example.darshan\", read_all=True)\n",
    "report.name_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original report for reference. Take note of the \"Loaded Records\" section\n",
    "report.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_records maybe filenames (or ids)\n",
    "# Note how only records of the STDIO module remain\n",
    "report.filter(name_records=['<STDIN>', '<STDOUT>', '<STDERR>']).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# name_records using a id\n",
    "# Note how only one POSIX, one MPI-IO and one LUSTRE record remain\n",
    "report.filter(name_records=[6301063301082038805]).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reduce all after filtering\n",
    "report.filter(pattern=\"*.hdf5\").reduce().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# only preserve some\n",
    "report.filter(name_records=[6301063301082038805]).reduce(mods=['POSIX', 'STDIO']).records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# expected to fail\n",
    "try:\n",
    "    pprint.pprint(report.summary['agg_ioops'])\n",
    "except:\n",
    "    print(\"IOOPS have not been aggregated for this report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.read_all() \n",
    "report.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report.summary['agg_ioops']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or fine grained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.mod_agg_iohist(\"MPI-IO\")  # to create the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.agg_ioops()               # to create the combined operation type summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Algebra (Experimental)\n",
    "\n",
    "Various operations are implemented to merge, combine and manipulate log records. This is useful for analysis task, but can also be used to construct performance projections or extrapolation.\n",
    "\n",
    "For convienience, we overload some of the operations provided by Python when they resemble intuitive equivalence to their mathematical counterparts. In particular, we enable the combination of different object types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darshan\n",
    "darshan.enable_experimental()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merging records\n",
    "from darshan.experimental.plots import plot_access_histogram\n",
    "from darshan.experimental.plots import plot_opcounts\n",
    "\n",
    "r1 = darshan.DarshanReport(\"example_logs/example.darshan\", read_all=True, dtype='numpy')\n",
    "r2 = darshan.DarshanReport(\"example_logs/example2.darshan\", read_all=True, dtype='numpy')\n",
    "rx = r1 + r2\n",
    "\n",
    "for r in [r1, r2, rx]:\n",
    "    plt = plot_opcounts(r)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply records with a scalar (think, four times the I/O load)\n",
    "#r1 = darshan.DarshanReport(\"example.darshan\", read_all=True)\n",
    "#rx = r1 * 4\n",
    "#plot_opcounts(rx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebase via timedelta\n",
    "#r1 = darshan.DarshanReport(\"example.darshan\", read_all=True)\n",
    "#dt = datetime.timedelta()\n",
    "#rx = r1 + dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darshan\n",
    "darshan.enable_experimental(verbose=False)\n",
    "\n",
    "r3 = darshan.DarshanReport(\"example_logs/example.darshan\", dtype='numpy')\n",
    "r3.mod_read_all_records('POSIX')\n",
    "\n",
    "from darshan.experimental.plots import plot_access_histogram\n",
    "plot_access_histogram(r3, mod='POSIX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darshan\n",
    "darshan.enable_experimental(verbose=False)\n",
    "\n",
    "r3 = darshan.DarshanReport(\"example_logs/example.darshan\", dtype='numpy')\n",
    "r3.mod_read_all_records('MPI-IO')\n",
    "\n",
    "from darshan.experimental.plots import plot_access_histogram\n",
    "plot_access_histogram(r3, mod='MPI-IO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import darshan\n",
    "darshan.enable_experimental(verbose=False)\n",
    "\n",
    "r3 = darshan.DarshanReport(\"example_logs/example.darshan\", dtype='numpy')\n",
    "r3.read_all()\n",
    "\n",
    "from darshan.experimental.plots import plot_opcounts\n",
    "plot_opcounts(r3, mod='POSIX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DXT Records\n",
    "\n",
    "DXT records are also supported, and can be loaded individually on a per module basis as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darshan\n",
    "\n",
    "report2 = darshan.DarshanReport(\"example_logs/dxt.darshan\")\n",
    "report2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report2.records['DXT_POSIX'][0]._records[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is easier to visualize or transform data to get an overview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prepared transformations\n",
    "# might require: pip install pillow\n",
    "from darshan.experimental.transforms.dxt2png import segment, wallclock\n",
    "\n",
    "report2.mod_read_all_dxt_records(\"DXT_POSIX\", dtype=\"dict\")  # need dict format for now\n",
    "rec = report2.records['DXT_POSIX'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallclock(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "report2.mod_read_all_dxt_records(\"DXT_POSIX\", dtype=\"pandas\") \n",
    "\n",
    "print(\"Write Segments:\")\n",
    "display(report2.records['DXT_POSIX'][2]['write_segments'])\n",
    "print(\"Read Segments:\")\n",
    "display(report2.records['DXT_POSIX'][2]['read_segments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise left for the reader ;P \n",
    "Implement a custom aggregator/summary function and commit it as a contribution to pydarshan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file: <darshan-repo>/darshan-util/pydarshan/darshan/experimental/aggregators/dxt_summary.py\n",
    "from darshan.report import *\n",
    "\n",
    "def dxt_summary(self):\n",
    "    \"\"\"\n",
    "    Count records for every name record.\n",
    "\n",
    "    Args:\n",
    "        mod_name (str): \n",
    "\n",
    "    Return:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    counts = {}\n",
    "\n",
    "    for mod, records in self.records.items():\n",
    "        for rec in records:\n",
    "            if rec['id'] not in counts:\n",
    "                counts[rec['id']] = {'name': self.name_records[rec['id']], 'counts': {}}\n",
    "\n",
    "            if mod not in counts[rec['id']]['counts']:\n",
    "                counts[rec['id']]['counts'][mod] = 1\n",
    "            else:\n",
    "                counts[rec['id']]['counts'][mod] += 1\n",
    "\n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data for Use in Third-Party Analysis\n",
    "\n",
    "Darshan logs may be used in contexts beyond our imagination. To make this effortless export in JSON is easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import darshan\n",
    "report = darshan.DarshanReport(\"example_logs/ior_hdf5_example.darshan\", read_all=True)\n",
    "report.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling?\n",
    "\n",
    "Currently, playing with two modes, both have their pros and cons.\n",
    "\n",
    "Generally, should expose errors and let users handle them. At the same time, just skipping invalid load requests does little harm but greatly improves convenience.\n",
    "\n",
    "Could add a switch to enable disable these guards :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report = darshan.DarshanReport(\"example_logs/example.darshan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.mod_read_all_records(\"MOD_ABC\") # Expect KeyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.mod_read_all_dxt_records(\"ABC\") # Expect warning, but not exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
