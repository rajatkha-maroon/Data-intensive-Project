{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8548495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import time\n",
    "import matplotlib.dates as md\n",
    "import dateutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59216296",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_data = pd.read_csv(\"ANL-ALCF-DJC-MIRA_20150101_20151231.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "375f2a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/2096999701.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  old_data['RUNTIME_SECONDS'][i] = str(0)\n"
     ]
    }
   ],
   "source": [
    "# clear runtime in old data\n",
    "for i in range(0,len(old_data['RUNTIME_SECONDS'])):\n",
    "    old_data['RUNTIME_SECONDS'][i] = str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6408ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Change_RunTime(old_data, sheet_name, new_file_path):\n",
    "    new_data = pd.read_excel(new_file_path, sheet_name = sheet_name)\n",
    "    new_data_num_rows = len(new_data['JOB_NAME'])\n",
    "    for i in range(0,new_data_num_rows):\n",
    "        tmp_line = old_data.loc[old_data['JOB_NAME'].isin([new_data['JOB_NAME'][i]])]\n",
    "        if(len(tmp_line) > 1):\n",
    "            print(\"Error, there are more than one job having the same name\")\n",
    "        old_data['RUNTIME_SECONDS'][tmp_line.index[0]] = new_data['New runtime'][i]\n",
    "    return old_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b5f8162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3970842545.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  old_data['RUNTIME_SECONDS'][tmp_line.index[0]] = new_data['New runtime'][i]\n"
     ]
    }
   ],
   "source": [
    "sheet_name = \"0% <= x < 16.7%\"\n",
    "new_file_path = \"Data-intensive-Project/traces/Mira_analysis/Data overlaps - Bucket percentiles.xlsx\"\n",
    "old_data = Change_RunTime(old_data, sheet_name, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5754034b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3970842545.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  old_data['RUNTIME_SECONDS'][tmp_line.index[0]] = new_data['New runtime'][i]\n"
     ]
    }
   ],
   "source": [
    "sheet_name = \"16.7% <= x < 33.3%\"\n",
    "new_file_path = \"Data-intensive-Project/traces/Mira_analysis/Data overlaps - Bucket percentiles.xlsx\"\n",
    "old_data = Change_RunTime(old_data, sheet_name, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87fe6009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3970842545.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  old_data['RUNTIME_SECONDS'][tmp_line.index[0]] = new_data['New runtime'][i]\n"
     ]
    }
   ],
   "source": [
    "sheet_name = \"33.3% <= x < 50.0%\"\n",
    "new_file_path = \"Data-intensive-Project/traces/Mira_analysis/Data overlaps - Bucket percentiles.xlsx\"\n",
    "old_data = Change_RunTime(old_data, sheet_name, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36173b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3970842545.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  old_data['RUNTIME_SECONDS'][tmp_line.index[0]] = new_data['New runtime'][i]\n"
     ]
    }
   ],
   "source": [
    "sheet_name = \"50.0% <= x < 66.7%\"\n",
    "new_file_path = \"Data-intensive-Project/traces/Mira_analysis/Data overlaps - Bucket percentiles.xlsx\"\n",
    "old_data = Change_RunTime(old_data, sheet_name, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1810f54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3970842545.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  old_data['RUNTIME_SECONDS'][tmp_line.index[0]] = new_data['New runtime'][i]\n"
     ]
    }
   ],
   "source": [
    "sheet_name = \"66.7% <= x < 83.3%\"\n",
    "new_file_path = \"Data-intensive-Project/traces/Mira_analysis/Data overlaps - Bucket percentiles.xlsx\"\n",
    "old_data = Change_RunTime(old_data, sheet_name, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d20fda27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check any row not modified runtime\n",
    "for i in range(0,len(old_data['RUNTIME_SECONDS'])):\n",
    "    if old_data['RUNTIME_SECONDS'][i] == 0:\n",
    "        print(f\"Error Job {old_data['JOB_NAME'][i]} RUNTIME_SECONDS is not modified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac0089d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trace_name = 'new_trace'\n",
    "DataFrame(old_data).to_csv(f\"{new_trace_name}.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ccf52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7176b353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82858/82858 [00:10<00:00, 8178.16it/s]\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/680772891.py:12: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  job_sorted_list = np.zeros([length], np.int)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82858/82858 [00:00<00:00, 2597027.63it/s]\n"
     ]
    }
   ],
   "source": [
    "#Split it to sub_traces\n",
    "\n",
    "def sort_job_id(data, sort_time):\n",
    "    job_tuples = []\n",
    "    length = len(data[sort_time])\n",
    "#     length = 5\n",
    "    for i in tqdm(range(0,length)):\n",
    "        job_tuples.append((i,md.date2num(dateutil.parser.parse(data[sort_time][i]))))\n",
    "#     print(job_tuples)\n",
    "    new_job_tuples = sorted(job_tuples, key=lambda time: time[1])\n",
    "#     print(new_job_tuples)\n",
    "    job_sorted_list = np.zeros([length], np.int)\n",
    "    for i in tqdm(range(0,length)):\n",
    "        job_sorted_list[i] = new_job_tuples[i][0]\n",
    "    return job_sorted_list\n",
    "\n",
    "# Sorted_start_time_list = sort_job_id(old_data,'START_TIMESTAMP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a47ddf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_traces(old_data, start_job_idx, end_job_idx, Sorted_start_time_list):\n",
    "    job_idx = []\n",
    "    for i in range(start_job_idx,end_job_idx):\n",
    "        job_id = Sorted_start_time_list[i]\n",
    "        job_idx.append(job_id)\n",
    "    return old_data.iloc[job_idx]\n",
    "\n",
    "# new_data = split_traces(old_data, 0, 5, Sorted_start_time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1562d49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       JOB_NAME  COBALT_JOBID MACHINE_NAME     QUEUED_TIMESTAMP  \\\n",
      "13  378419.mira        378419         mira  2014-12-09 09:09:04   \n",
      "1   383815.mira        383815         mira  2014-12-18 17:39:38   \n",
      "25  385410.mira        385410         mira  2014-12-22 10:41:47   \n",
      "28  383816.mira        383816         mira  2014-12-18 17:40:01   \n",
      "11  386304.mira        386304         mira  2014-12-23 17:21:46   \n",
      "\n",
      "    QUEUED_DATE_ID      START_TIMESTAMP  START_DATE_ID        END_TIMESTAMP  \\\n",
      "13        20141209  2014-12-31 13:56:07       20141231  2015-01-01 01:26:13   \n",
      "1         20141218  2014-12-31 18:19:20       20141231  2015-01-01 00:19:57   \n",
      "25        20141222  2014-12-31 19:54:52       20141231  2015-01-01 01:55:51   \n",
      "28        20141218  2014-12-31 19:56:26       20141231  2015-01-01 01:57:16   \n",
      "11        20141223  2014-12-31 19:56:59       20141231  2015-01-01 01:20:40   \n",
      "\n",
      "    END_DATE_ID  USERNAME_GENID  ...  IS_SUBBLOCK IS_SUBBLOCK_ONLY  \\\n",
      "13     20150101   3671037454004  ...            0                0   \n",
      "1      20150101  61648062878124  ...            0                0   \n",
      "25     20150101   5283526659609  ...            0                0   \n",
      "28     20150101  61648062878124  ...            0                0   \n",
      "11     20150101  72412967808736  ...            0                0   \n",
      "\n",
      "    IS_MULTILOCATION_ONLY IS_MULTILOCATION_SUBBLOCK  IS_CONSECUTIVE_ONLY  \\\n",
      "13                      0                         0                    0   \n",
      "1                       0                         0                    0   \n",
      "25                      0                         0                    0   \n",
      "28                      0                         0                    0   \n",
      "11                      0                         0                    0   \n",
      "\n",
      "    IS_SINGLE_ONLY  IS_NO_TASKS  IS_OTHER OVERBURN_CORE_HOURS  IS_OVERBURN  \n",
      "13               1            0         0                 0.0            0  \n",
      "1                1            0         0                 0.0            0  \n",
      "25               1            0         0                 0.0            0  \n",
      "28               1            0         0                 0.0            0  \n",
      "11               1            0         0                 0.0            0  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b22dc15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82858/82858 [00:09<00:00, 8560.33it/s]\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/680772891.py:12: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  job_sorted_list = np.zeros([length], np.int)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82858/82858 [00:00<00:00, 2590851.52it/s]\n",
      " 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 41/42 [00:01<00:00, 23.45it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 82858 is out of bounds for axis 0 with size 82858",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m num_jobs_per_fig \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,total_jobs,num_jobs_per_fig)):\n\u001b[0;32m----> 9\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[43msplit_traces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mold_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mnum_jobs_per_fig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSorted_start_time_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     DataFrame(new_data)\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_traces/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_trace_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39mnum_jobs_per_fig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[49], line 4\u001b[0m, in \u001b[0;36msplit_traces\u001b[0;34m(old_data, start_job_idx, end_job_idx, Sorted_start_time_list)\u001b[0m\n\u001b[1;32m      2\u001b[0m job_idx \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_job_idx,end_job_idx):\n\u001b[0;32m----> 4\u001b[0m     job_id \u001b[38;5;241m=\u001b[39m \u001b[43mSorted_start_time_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m     job_idx\u001b[38;5;241m.\u001b[39mappend(job_id)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m old_data\u001b[38;5;241m.\u001b[39miloc[job_idx]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 82858 is out of bounds for axis 0 with size 82858"
     ]
    }
   ],
   "source": [
    "new_trace_name = 'new_trace'\n",
    "old_data = pd.read_csv(f\"{new_trace_name}.csv\")\n",
    "Sorted_start_time_list = sort_job_id(old_data,'START_TIMESTAMP')\n",
    "\n",
    "\n",
    "total_jobs = len(old_data['LOCATION'])\n",
    "num_jobs_per_fig = 2000\n",
    "for i in tqdm(range(0,total_jobs,num_jobs_per_fig)):\n",
    "    start = i\n",
    "    end = i+num_jobs_per_fig\n",
    "    new_data = split_traces(old_data, i, i+num_jobs_per_fig, Sorted_start_time_list)\n",
    "    DataFrame(new_data).to_csv(f\"new_traces/{new_trace_name}_{i}_{i+num_jobs_per_fig}.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8853c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b09e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
