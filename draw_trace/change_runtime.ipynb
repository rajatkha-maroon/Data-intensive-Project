{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d8548495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import time\n",
    "import matplotlib.dates as md\n",
    "import dateutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "145c578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Change_RunTime(old_data, sheet_name, new_file_path):\n",
    "    new_data = pd.read_excel(new_file_path, sheet_name = sheet_name)\n",
    "    new_data_num_rows = len(new_data['JOB_NAME'])\n",
    "    old_runtime = 0\n",
    "    new_runtime = 0\n",
    "    for i in range(0,new_data_num_rows):\n",
    "        tmp_line = old_data.loc[old_data['JOB_NAME'].isin([new_data['JOB_NAME'][i]])]\n",
    "        if(len(tmp_line) > 1):\n",
    "            print(\"Error, there are more than one job having the same name\")\n",
    "        old_runtime += np.float(old_data['RUNTIME_SECONDS'][tmp_line.index[0]])\n",
    "        new_runtime += np.float(new_data['New runtime'][i])\n",
    "        old_data['RUNTIME_SECONDS'][tmp_line.index[0]] = new_data['New runtime'][i]\n",
    "    reduced_ratio = (old_runtime - new_runtime) / old_runtime * 100\n",
    "    print(f\"{sheet_name}: old_runtime = {old_runtime}, new_runtime = {new_runtime}, reduced_ratio = {reduced_ratio}%, reduced_hours = {(old_runtime - new_runtime)/3600}\")\n",
    "    return old_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "760024ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Selec_Job_name(old_file_path, sheet_name, new_file_path):\n",
    "    new_data = pd.read_excel(new_file_path, sheet_name = sheet_name)\n",
    "    new_data_num_rows = len(new_data['JOB_NAME'])\n",
    "    job_names = []\n",
    "    for i in range(0,new_data_num_rows):\n",
    "        job_names.append(new_data['JOB_NAME'][i])\n",
    "        \n",
    "    old_data = pd.read_csv(old_file_path)\n",
    "    old_sheet_data = old_data.loc[old_data['JOB_NAME'].isin(job_names)]\n",
    "    DataFrame(old_sheet_data).to_csv(f\"old_parallel_traces/{sheet_name}.csv\", index=False, header=False, sep=';')\n",
    "    \n",
    "    old_sheet_data2 = Change_RunTime(old_sheet_data, sheet_name, new_file_path)\n",
    "    DataFrame(old_sheet_data2).to_csv(f\"new_parallel_traces/{sheet_name}.csv\", index=False, header=False, sep=';')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "59216296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  old_runtime += np.float(old_data['RUNTIME_SECONDS'][tmp_line.index[0]])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  new_runtime += np.float(new_data['New runtime'][i])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  old_data['RUNTIME_SECONDS'][tmp_line.index[0]] = new_data['New runtime'][i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% <= x < 16.7%: old_runtime = 23519357.0, new_runtime = 22042222.905599866, reduced_ratio = 6.280503733159601%, reduced_hours = 410.3150262222594\n"
     ]
    }
   ],
   "source": [
    "sheet_name = \"0% <= x < 16.7%\"\n",
    "new_file_path = \"Data-intensive-Project/traces/Mira_analysis/Data overlaps - Bucket percentiles.xlsx\"\n",
    "Selec_Job_name(\"ANL-ALCF-DJC-MIRA_20150101_20151231.csv\",sheet_name,new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "40836800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  old_runtime += np.float(old_data['RUNTIME_SECONDS'][tmp_line.index[0]])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  new_runtime += np.float(new_data['New runtime'][i])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  old_data['RUNTIME_SECONDS'][tmp_line.index[0]] = new_data['New runtime'][i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.7% <= x < 33.3%: old_runtime = 18498254.0, new_runtime = 17355851.44352743, reduced_ratio = 6.175731809459259%, reduced_hours = 317.3340434646027\n"
     ]
    }
   ],
   "source": [
    "sheet_name = \"16.7% <= x < 33.3%\"\n",
    "new_file_path = \"Data-intensive-Project/traces/Mira_analysis/Data overlaps - Bucket percentiles.xlsx\"\n",
    "Selec_Job_name(\"ANL-ALCF-DJC-MIRA_20150101_20151231.csv\",sheet_name,new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "f7eb9b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.3% <= x < 50.0%: old_runtime = 597672.0, new_runtime = 560505.3411775699, reduced_ratio = 6.218571193301688%, reduced_hours = 10.324071895119463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  old_runtime += np.float(old_data['RUNTIME_SECONDS'][tmp_line.index[0]])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  new_runtime += np.float(new_data['New runtime'][i])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  old_data['RUNTIME_SECONDS'][tmp_line.index[0]] = new_data['New runtime'][i]\n"
     ]
    }
   ],
   "source": [
    "sheet_name = \"33.3% <= x < 50.0%\"\n",
    "new_file_path = \"Data-intensive-Project/traces/Mira_analysis/Data overlaps - Bucket percentiles.xlsx\"\n",
    "Selec_Job_name(\"ANL-ALCF-DJC-MIRA_20150101_20151231.csv\",sheet_name,new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "d3a5c787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0% <= x < 66.7%: old_runtime = 72782.0, new_runtime = 68289.06574543215, reduced_ratio = 6.173139312697991%, reduced_hours = 1.2480372929355144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  old_runtime += np.float(old_data['RUNTIME_SECONDS'][tmp_line.index[0]])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  new_runtime += np.float(new_data['New runtime'][i])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  old_data['RUNTIME_SECONDS'][tmp_line.index[0]] = new_data['New runtime'][i]\n"
     ]
    }
   ],
   "source": [
    "sheet_name = \"50.0% <= x < 66.7%\"\n",
    "new_file_path = \"Data-intensive-Project/traces/Mira_analysis/Data overlaps - Bucket percentiles.xlsx\"\n",
    "Selec_Job_name(\"ANL-ALCF-DJC-MIRA_20150101_20151231.csv\",sheet_name,new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "07d22416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.7% <= x < 83.3%: old_runtime = 217922.0, new_runtime = 204092.90189403424, reduced_ratio = 6.345893533450392%, reduced_hours = 3.8414161405460456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  old_runtime += np.float(old_data['RUNTIME_SECONDS'][tmp_line.index[0]])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  new_runtime += np.float(new_data['New runtime'][i])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  old_data['RUNTIME_SECONDS'][tmp_line.index[0]] = new_data['New runtime'][i]\n"
     ]
    }
   ],
   "source": [
    "sheet_name = \"66.7% <= x < 83.3%\"\n",
    "new_file_path = \"Data-intensive-Project/traces/Mira_analysis/Data overlaps - Bucket percentiles.xlsx\"\n",
    "Selec_Job_name(\"ANL-ALCF-DJC-MIRA_20150101_20151231.csv\",sheet_name,new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfa40a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "c2327633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82858/82858 [00:10<00:00, 7951.74it/s]\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3049484925.py:12: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  job_sorted_list = np.zeros([length], np.int)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82858/82858 [00:00<00:00, 2455342.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:02<00:00, 14.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# new_trace_name = 'new_trace'\n",
    "# old_data = pd.read_csv(f\"{new_trace_name}.csv\", sep=';')\n",
    "Sorted_start_time_list = sort_job_id(old_data,'START_TIMESTAMP')\n",
    "\n",
    "\n",
    "total_jobs = len(old_data['LOCATION'])\n",
    "num_jobs_per_fig = 2000\n",
    "job_tuples = []\n",
    "for i in tqdm(range(0,total_jobs,num_jobs_per_fig)):\n",
    "    start = i\n",
    "    end = i + num_jobs_per_fig\n",
    "    if(end > total_jobs):\n",
    "        end = total_jobs\n",
    "    new_data = split_traces(old_data, start, end, Sorted_start_time_list)\n",
    "    \n",
    "    \n",
    "    num_total_jobs = 0\n",
    "    num_parallel_jobs = 0\n",
    "    total_run_time = np.float64(0)\n",
    "    for j in range(i,i+len(new_data['NUM_TASKS_MULTILOCATION'])):\n",
    "        if(int(new_data['NUM_TASKS_MULTILOCATION'][Sorted_start_time_list[j]]) > 0):\n",
    "            num_parallel_jobs += 1\n",
    "        num_total_jobs += 1\n",
    "        total_run_time += np.float64(new_data['RUNTIME_SECONDS'][Sorted_start_time_list[j]])\n",
    "    ratio = np.float64(num_parallel_jobs)/np.float64(num_total_jobs)\n",
    "    output = f\"{start}_{end} has num_parallel_jobs = {num_parallel_jobs}, num_total_jobs = {num_total_jobs}, ratio = {ratio}, total_run_time = {total_run_time}\"\n",
    "    \n",
    "    job_tuples.append((start, end, num_parallel_jobs, num_total_jobs, ratio, output, total_run_time))\n",
    "    \n",
    "    \n",
    "    DataFrame(new_data).to_csv(f\"old_traces/{new_trace_name}_{start}_{end}.csv\", index=False, header=False, sep=';')\n",
    "    \n",
    "new_job_tuples = sorted(job_tuples, key=lambda time: time[4], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "ebebec89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38000_40000 has num_parallel_jobs = 135, num_total_jobs = 2000, ratio = 0.0675, total_run_time = 10751386.0\n",
      "80000_82000 has num_parallel_jobs = 84, num_total_jobs = 2000, ratio = 0.042, total_run_time = 16527544.0\n",
      "2000_4000 has num_parallel_jobs = 83, num_total_jobs = 2000, ratio = 0.0415, total_run_time = 15860576.0\n",
      "78000_80000 has num_parallel_jobs = 82, num_total_jobs = 2000, ratio = 0.041, total_run_time = 14314559.0\n",
      "0_2000 has num_parallel_jobs = 79, num_total_jobs = 2000, ratio = 0.0395, total_run_time = 15757194.0\n",
      "14000_16000 has num_parallel_jobs = 79, num_total_jobs = 2000, ratio = 0.0395, total_run_time = 9362739.0\n",
      "20000_22000 has num_parallel_jobs = 79, num_total_jobs = 2000, ratio = 0.0395, total_run_time = 12775560.0\n",
      "40000_42000 has num_parallel_jobs = 78, num_total_jobs = 2000, ratio = 0.039, total_run_time = 6799682.0\n",
      "76000_78000 has num_parallel_jobs = 74, num_total_jobs = 2000, ratio = 0.037, total_run_time = 16666497.0\n",
      "22000_24000 has num_parallel_jobs = 68, num_total_jobs = 2000, ratio = 0.034, total_run_time = 12424854.0\n",
      "36000_38000 has num_parallel_jobs = 66, num_total_jobs = 2000, ratio = 0.033, total_run_time = 10924839.0\n",
      "10000_12000 has num_parallel_jobs = 65, num_total_jobs = 2000, ratio = 0.0325, total_run_time = 15212948.0\n",
      "12000_14000 has num_parallel_jobs = 65, num_total_jobs = 2000, ratio = 0.0325, total_run_time = 10336610.0\n",
      "18000_20000 has num_parallel_jobs = 63, num_total_jobs = 2000, ratio = 0.0315, total_run_time = 12397391.0\n",
      "6000_8000 has num_parallel_jobs = 62, num_total_jobs = 2000, ratio = 0.031, total_run_time = 13940219.0\n",
      "32000_34000 has num_parallel_jobs = 62, num_total_jobs = 2000, ratio = 0.031, total_run_time = 10732029.0\n",
      "52000_54000 has num_parallel_jobs = 62, num_total_jobs = 2000, ratio = 0.031, total_run_time = 7347448.0\n",
      "82000_82858 has num_parallel_jobs = 26, num_total_jobs = 858, ratio = 0.030303030303030304, total_run_time = 8646958.0\n",
      "16000_18000 has num_parallel_jobs = 54, num_total_jobs = 2000, ratio = 0.027, total_run_time = 11374331.0\n",
      "74000_76000 has num_parallel_jobs = 51, num_total_jobs = 2000, ratio = 0.0255, total_run_time = 18667472.0\n",
      "24000_26000 has num_parallel_jobs = 47, num_total_jobs = 2000, ratio = 0.0235, total_run_time = 10323607.0\n",
      "8000_10000 has num_parallel_jobs = 46, num_total_jobs = 2000, ratio = 0.023, total_run_time = 10798116.0\n",
      "72000_74000 has num_parallel_jobs = 44, num_total_jobs = 2000, ratio = 0.022, total_run_time = 14880467.0\n",
      "26000_28000 has num_parallel_jobs = 42, num_total_jobs = 2000, ratio = 0.021, total_run_time = 13954818.0\n",
      "66000_68000 has num_parallel_jobs = 39, num_total_jobs = 2000, ratio = 0.0195, total_run_time = 13919856.0\n",
      "4000_6000 has num_parallel_jobs = 38, num_total_jobs = 2000, ratio = 0.019, total_run_time = 13948315.0\n",
      "50000_52000 has num_parallel_jobs = 38, num_total_jobs = 2000, ratio = 0.019, total_run_time = 7022241.0\n",
      "54000_56000 has num_parallel_jobs = 38, num_total_jobs = 2000, ratio = 0.019, total_run_time = 4607875.0\n",
      "30000_32000 has num_parallel_jobs = 30, num_total_jobs = 2000, ratio = 0.015, total_run_time = 11805630.0\n",
      "34000_36000 has num_parallel_jobs = 30, num_total_jobs = 2000, ratio = 0.015, total_run_time = 9936013.0\n",
      "68000_70000 has num_parallel_jobs = 26, num_total_jobs = 2000, ratio = 0.013, total_run_time = 18298380.0\n",
      "28000_30000 has num_parallel_jobs = 20, num_total_jobs = 2000, ratio = 0.01, total_run_time = 9763515.0\n",
      "70000_72000 has num_parallel_jobs = 18, num_total_jobs = 2000, ratio = 0.009, total_run_time = 17140740.0\n",
      "48000_50000 has num_parallel_jobs = 16, num_total_jobs = 2000, ratio = 0.008, total_run_time = 2470338.0\n",
      "62000_64000 has num_parallel_jobs = 14, num_total_jobs = 2000, ratio = 0.007, total_run_time = 4986647.0\n",
      "58000_60000 has num_parallel_jobs = 13, num_total_jobs = 2000, ratio = 0.0065, total_run_time = 3384676.0\n",
      "42000_44000 has num_parallel_jobs = 11, num_total_jobs = 2000, ratio = 0.0055, total_run_time = 2790522.0\n",
      "56000_58000 has num_parallel_jobs = 11, num_total_jobs = 2000, ratio = 0.0055, total_run_time = 4178310.0\n",
      "44000_46000 has num_parallel_jobs = 8, num_total_jobs = 2000, ratio = 0.004, total_run_time = 3021307.0\n",
      "46000_48000 has num_parallel_jobs = 8, num_total_jobs = 2000, ratio = 0.004, total_run_time = 3129200.0\n",
      "60000_62000 has num_parallel_jobs = 7, num_total_jobs = 2000, ratio = 0.0035, total_run_time = 3752062.0\n",
      "64000_66000 has num_parallel_jobs = 7, num_total_jobs = 2000, ratio = 0.0035, total_run_time = 4740530.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(new_job_tuples)):\n",
    "    print(new_job_tuples[i][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0a7d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "cfd442fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clear runtime in old data\n",
    "# for i in range(0,len(old_data['RUNTIME_SECONDS'])):\n",
    "#     old_data['RUNTIME_SECONDS'][i] = str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8de99d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "b377fdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  old_runtime += np.float(old_data['RUNTIME_SECONDS'][tmp_line.index[0]])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  new_runtime += np.float(new_data['New runtime'][i])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  old_data['RUNTIME_SECONDS'][tmp_line.index[0]] = new_data['New runtime'][i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% <= x < 16.7%: old_runtime = 23519357.0, new_runtime = 22042222.905599866, reduced_ratio = 6.280503733159601%, reduced_hours = 410.3150262222594\n"
     ]
    }
   ],
   "source": [
    "sheet_name = \"0% <= x < 16.7%\"\n",
    "new_file_path = \"Data-intensive-Project/traces/Mira_analysis/Data overlaps - Bucket percentiles.xlsx\"\n",
    "old_data = Change_RunTime(old_data, sheet_name, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4d0c54be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  old_runtime += np.float(old_data['RUNTIME_SECONDS'][tmp_line.index[0]])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  new_runtime += np.float(new_data['New runtime'][i])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  old_data['RUNTIME_SECONDS'][tmp_line.index[0]] = new_data['New runtime'][i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.7% <= x < 33.3%: old_runtime = 18498254.0, new_runtime = 17355851.44352743, reduced_ratio = 6.175731809459259%, reduced_hours = 317.3340434646027\n"
     ]
    }
   ],
   "source": [
    "sheet_name = \"16.7% <= x < 33.3%\"\n",
    "new_file_path = \"Data-intensive-Project/traces/Mira_analysis/Data overlaps - Bucket percentiles.xlsx\"\n",
    "old_data = Change_RunTime(old_data, sheet_name, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "52a87d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.3% <= x < 50.0%: old_runtime = 597672.0, new_runtime = 560505.3411775699, reduced_ratio = 6.218571193301688%, reduced_hours = 10.324071895119463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  old_runtime += np.float(old_data['RUNTIME_SECONDS'][tmp_line.index[0]])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  new_runtime += np.float(new_data['New runtime'][i])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  old_data['RUNTIME_SECONDS'][tmp_line.index[0]] = new_data['New runtime'][i]\n"
     ]
    }
   ],
   "source": [
    "sheet_name = \"33.3% <= x < 50.0%\"\n",
    "new_file_path = \"Data-intensive-Project/traces/Mira_analysis/Data overlaps - Bucket percentiles.xlsx\"\n",
    "old_data = Change_RunTime(old_data, sheet_name, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "36173b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0% <= x < 66.7%: old_runtime = 72782.0, new_runtime = 68289.06574543215, reduced_ratio = 6.173139312697991%, reduced_hours = 1.2480372929355144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:10: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  old_runtime += np.float(old_data['RUNTIME_SECONDS'][tmp_line.index[0]])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  new_runtime += np.float(new_data['New runtime'][i])\n",
      "/var/folders/ch/qkmvbw8d40d5864w96srwgpr0000gn/T/ipykernel_37658/3926385617.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  old_data['RUNTIME_SECONDS'][tmp_line.index[0]] = new_data['New runtime'][i]\n"
     ]
    }
   ],
   "source": [
    "sheet_name = \"50.0% <= x < 66.7%\"\n",
    "new_file_path = \"Data-intensive-Project/traces/Mira_analysis/Data overlaps - Bucket percentiles.xlsx\"\n",
    "old_data = Change_RunTime(old_data, sheet_name, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1810f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_name = \"66.7% <= x < 83.3%\"\n",
    "new_file_path = \"Data-intensive-Project/traces/Mira_analysis/Data overlaps - Bucket percentiles.xlsx\"\n",
    "old_data = Change_RunTime(old_data, sheet_name, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20fda27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check any row not modified runtime\n",
    "for i in range(0,len(old_data['RUNTIME_SECONDS'])):\n",
    "    if int(old_data['RUNTIME_SECONDS'][i]) == 0:\n",
    "        print(f\"Error Job {old_data['JOB_NAME'][i]} RUNTIME_SECONDS is not modified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de395a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trace_name = 'new_trace'\n",
    "DataFrame(old_data).to_csv(f\"{new_trace_name}.csv\", index=False, header=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e544b15a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d42f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split it to sub_traces\n",
    "\n",
    "def sort_job_id(data, sort_time):\n",
    "    job_tuples = []\n",
    "    length = len(data[sort_time])\n",
    "#     length = 5\n",
    "    for i in tqdm(range(0,length)):\n",
    "        job_tuples.append((i,md.date2num(dateutil.parser.parse(data[sort_time][i]))))\n",
    "#     print(job_tuples)\n",
    "    new_job_tuples = sorted(job_tuples, key=lambda time: time[1])\n",
    "#     print(new_job_tuples)\n",
    "    job_sorted_list = np.zeros([length], np.int)\n",
    "    for i in tqdm(range(0,length)):\n",
    "        job_sorted_list[i] = new_job_tuples[i][0]\n",
    "    return job_sorted_list\n",
    "\n",
    "# Sorted_start_time_list = sort_job_id(old_data,'START_TIMESTAMP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de65460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_traces(old_data, start_job_idx, end_job_idx, Sorted_start_time_list):\n",
    "    job_idx = []\n",
    "    for i in range(start_job_idx,end_job_idx):\n",
    "        job_id = Sorted_start_time_list[i]\n",
    "        job_idx.append(job_id)\n",
    "    return old_data.iloc[job_idx]\n",
    "\n",
    "# new_data = split_traces(old_data, 0, 5, Sorted_start_time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b56623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa05e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_trace_name = 'new_trace'\n",
    "# old_data = pd.read_csv(f\"{new_trace_name}.csv\", sep=';')\n",
    "Sorted_start_time_list = sort_job_id(old_data,'START_TIMESTAMP')\n",
    "\n",
    "\n",
    "total_jobs = len(old_data['LOCATION'])\n",
    "num_jobs_per_fig = 2000\n",
    "job_tuples2 = []\n",
    "for i in tqdm(range(0,total_jobs,num_jobs_per_fig)):\n",
    "    start = i\n",
    "    end = i + num_jobs_per_fig\n",
    "    if(end > total_jobs):\n",
    "        end = total_jobs\n",
    "    new_data = split_traces(old_data, start, end, Sorted_start_time_list)\n",
    "    \n",
    "    \n",
    "    num_total_jobs = 0\n",
    "    num_parallel_jobs = 0\n",
    "    total_run_time = np.float64(0)\n",
    "    for j in range(i,i+len(new_data['NUM_TASKS_MULTILOCATION'])):\n",
    "        if(int(new_data['NUM_TASKS_MULTILOCATION'][Sorted_start_time_list[j]]) > 0):\n",
    "            num_parallel_jobs += 1\n",
    "        num_total_jobs += 1\n",
    "        total_run_time += np.float64(new_data['RUNTIME_SECONDS'][Sorted_start_time_list[j]])\n",
    "    ratio = np.float64(num_parallel_jobs)/np.float64(num_total_jobs)\n",
    "    output = f\"{start}_{end} has num_parallel_jobs = {num_parallel_jobs}, num_total_jobs = {num_total_jobs}, ratio = {ratio}, total_run_time = {total_run_time}\"\n",
    "    \n",
    "    job_tuples2.append((start, end, num_parallel_jobs, num_total_jobs, ratio, output, total_run_time, np.float(0), np.float(0)))\n",
    "    \n",
    "    \n",
    "    DataFrame(new_data).to_csv(f\"old_traces/{new_trace_name}_{start}_{end}.csv\", index=False, header=False, sep=';')\n",
    "    \n",
    "new_job_tuples2 = sorted(job_tuples2, key=lambda time: time[4], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # new_trace_name = 'new_trace'\n",
    "# # old_data = pd.read_csv(f\"{new_trace_name}.csv\", sep=';')\n",
    "# Sorted_start_time_list = sort_job_id(old_data,'START_TIMESTAMP')\n",
    "\n",
    "\n",
    "# total_jobs = len(old_data['LOCATION'])\n",
    "# num_jobs_per_fig = 2000\n",
    "# job_tuples = []\n",
    "# for i in tqdm(range(0,total_jobs,num_jobs_per_fig)):\n",
    "#     start = i\n",
    "#     end = i + num_jobs_per_fig\n",
    "#     if(end > total_jobs):\n",
    "#         end = total_jobs\n",
    "#     new_data = split_traces(old_data, start, end, Sorted_start_time_list)\n",
    "    \n",
    "    \n",
    "#     num_total_jobs = 0\n",
    "#     num_parallel_jobs = 0\n",
    "#     for j in range(i,i+len(new_data['NUM_TASKS_MULTILOCATION'])):\n",
    "#         if(int(new_data['NUM_TASKS_MULTILOCATION'][Sorted_start_time_list[j]]) > 0):\n",
    "#             num_parallel_jobs += 1\n",
    "#         num_total_jobs += 1\n",
    "#     ratio = np.float64(num_parallel_jobs)/np.float64(num_total_jobs)\n",
    "#     output = f\"{start}_{end} has num_parallel_jobs = {num_parallel_jobs}, num_total_jobs = {num_total_jobs}, ratio = {ratio}\"\n",
    "    \n",
    "#     job_tuples.append((start, end, num_parallel_jobs, num_total_jobs, ratio, output))\n",
    "    \n",
    "    \n",
    "#     DataFrame(new_data).to_csv(f\"new_traces/{new_trace_name}_{start}_{end}.csv\", index=False, header=False, sep=';')\n",
    "    \n",
    "# new_job_tuples = sorted(job_tuples, key=lambda time: time[4], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(new_job_tuples2)):\n",
    "    print(new_job_tuples2[i][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_tuples3 = []\n",
    "for i in range(len(job_tuples2)):\n",
    "    if job_tuples[i][0] != job_tuples2[i][0]:\n",
    "        print(\"Error!!\")\n",
    "    if job_tuples[i][1] != job_tuples2[i][1]:\n",
    "        print(\"Error!!\")\n",
    "    change_ratio = (job_tuples[i][6] - job_tuples2[i][6]) / job_tuples[i][6] * 100\n",
    "    output = f\"{job_tuples2[i][0]}_{job_tuples2[i][1]} has num_parallel_jobs = {job_tuples2[i][2]}, num_total_jobs = {job_tuples2[i][3]}, ratio = {job_tuples2[i][4]}, old_run_time = {job_tuples[i][6]}, new_run_time = {job_tuples2[i][6]}, reduced_percentage = {change_ratio}%, reduced_hours = {(job_tuples[i][6] - job_tuples2[i][6])/3600}\"\n",
    "    job_tuples3.append((job_tuples2[i][0],job_tuples2[i][1],job_tuples2[i][2],job_tuples2[i][3],job_tuples2[i][4],output,job_tuples2[i][6],job_tuples[i][6],change_ratio))\n",
    "    \n",
    "new_job_tuples3 = sorted(job_tuples3, key=lambda time: time[4], reverse=True)\n",
    "\n",
    "for i in range(0,len(new_job_tuples3)):\n",
    "#     output = f\"{job_tuples3[i][0]}_{job_tuples3[i][1]} has num_parallel_jobs = {job_tuples3[i][2]}, num_total_jobs = {job_tuples3[i][3]}, ratio = {job_tuples3[i][4]}, old_run_time = {job_tuples3[i][7]}, new_run_time = {job_tuples3[i][6]}, reduced_percentage = {job_tuples3[i][8]}\"\n",
    "    print(new_job_tuples3[i][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5def009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_job_tuples4 = sorted(job_tuples3, key=lambda time: time[8], reverse=True)\n",
    "for i in range(0,len(new_job_tuples4)):\n",
    "    print(new_job_tuples4[i][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23392161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a7523b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
